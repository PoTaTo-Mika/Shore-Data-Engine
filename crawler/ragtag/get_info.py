import requests
from bs4 import BeautifulSoup
import json

url = "https://archive.ragtag.moe/channels"
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

try:
    response = requests.get(url, headers=headers, timeout=10)
    response.raise_for_status()  # å¦‚æœçŠ¶æ€ç ä¸æ˜¯ 200ï¼ŒæŠ›å‡ºå¼‚å¸¸
    
    soup = BeautifulSoup(response.text, 'html.parser')
    script_tag = soup.find('script', id='__NEXT_DATA__')

    if script_tag:
        data = json.loads(script_tag.string)
        
        # ä½¿ç”¨ .get() çº§è”è·å–ï¼Œé˜²æ­¢ä¸­é—´å±‚çº§ç¼ºå¤±å¯¼è‡´å´©æºƒ
        props = data.get('props', {})
        page_props = props.get('pageProps', {})
        channels = page_props.get('channels', [])

        if channels:
            print(f"âœ… æˆåŠŸæå–åˆ° {len(channels)} ä¸ªé¢‘é“ä¿¡æ¯")
            with open('channels.json', 'w', encoding='utf-8') as f:
                json.dump(channels, f, ensure_ascii=False, indent=2)
            print("ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ° channels.json")
        else:
            print("âš ï¸ æœªåœ¨ JSON ä¸­æ‰¾åˆ° channels å­—æ®µ")
    else:
        print("âŒ æœªæ‰¾åˆ° __NEXT_DATA__ æ ‡ç­¾ï¼Œç½‘ç«™å¯èƒ½æ›´æ”¹äº†æ¸²æŸ“æ–¹å¼")

except requests.exceptions.RequestException as e:
    print(f"ğŸš€ ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
except json.JSONDecodeError:
    print("ğŸš« JSON è§£æå¤±è´¥")


