import httpx
import json
from bs4 import BeautifulSoup
import re
import os
import time
from pathlib import Path
from urllib.parse import urljoin, unquote

BASE_URL = "https://voicewiki.cn"

def get_voice_page_urls(character_page_url: str, session: httpx.Client) -> list[str]:
    """
    ä»è§’è‰²çš„ä¸»ä»‹ç»é¡µé¢è·å–æ‰€æœ‰è¯­éŸ³å­é¡µé¢çš„URLã€‚
    """
    print(f"æ­£åœ¨è®¿é—®è§’è‰²ä¸»é¡µ: {character_page_url}")
    try:
        response = session.get(character_page_url)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        links = soup.select('div[style*="background-color:rgba(49,53,72,0.7)"] a[href*="/"]')
        page_urls = set()
        for link in links:
            href = link.get('href')
            if href and href.startswith('/wiki/') and href.count('/') > 1:
                full_url = urljoin(BASE_URL, href)
                page_urls.add(full_url)
                
        if not page_urls:
            print("è­¦å‘Šï¼šåœ¨ä¸»é¡µä¸Šæœªèƒ½è‡ªåŠ¨æ‰¾åˆ°ä»»ä½•è¯­éŸ³å­é¡µé¢é“¾æ¥ã€‚è¯·æ£€æŸ¥URLæ˜¯å¦ä¸ºè§’è‰²ä¸»é¡µã€‚")
        else:
            print(f"åœ¨ä¸»é¡µä¸Šæ‰¾åˆ°äº† {len(page_urls)} ä¸ªè¯­éŸ³é¡µé¢é“¾æ¥ã€‚")

        return list(page_urls)
        
    except httpx.RequestError as e:
        print(f"è¯·æ±‚è§’è‰²ä¸»é¡µæ—¶å‡ºé”™: {e}")
        return []

def parse_voice_page(html_content: str, page_url: str) -> dict:
    """
    å°†è¯­éŸ³å­é¡µé¢çš„HTMLå†…å®¹è½¬æ¢ä¸ºç»“æ„åŒ–çš„å­—å…¸æ•°æ®ã€‚
    ä½¿ç”¨æ›´å¥å£®çš„é€‰æ‹©å™¨æ¥å®šä½éŸ³é¢‘æ¡ç›®ã€‚
    """
    soup = BeautifulSoup(html_content, 'html.parser')
    
    title_element = soup.find('span', id='cosmos-title-text')
    page_title = title_element.text.strip() if title_element else "æœªçŸ¥æ ‡é¢˜"
    
    audio_data = []
    
    # ã€æ ¸å¿ƒä¿®æ”¹ã€‘
    # 1. ç›´æ¥æŸ¥æ‰¾æ‰€æœ‰æ˜ç¡®æ ‡è¯†ä¸ºéŸ³é¢‘æ’­æ”¾å™¨çš„div
    audio_divs = soup.find_all('div', class_='downloadable-audio')
    
    if audio_divs:
        # 2. éå†æ‰¾åˆ°çš„divï¼Œå¹¶ä»¥å…¶çˆ¶çº§tableä½œä¸ºå¤„ç†å•å…ƒ
        for div in audio_divs:
            table_container = div.find_parent('table')
            if not table_container:
                continue

            audio_link = table_container.find('a', class_='internal', href=re.compile(r'\.ogg$'))
            if audio_link:
                audio_url = urljoin(BASE_URL, audio_link['href'])
                filename = unquote(audio_link['title'])
                
                text_element = table_container.find('span', lang='zh-Hans-CN')
                chinese_text = text_element.text.strip() if text_element else "æ— æ–‡æœ¬"
                
                id_match = re.search(r'([A-F0-9]{8})\.0B2', filename) or re.search(r'/([^/]+?)\.ogg', unquote(audio_url))
                audio_id = id_match.group(1).split('/')[-1] if id_match else f"æœªçŸ¥ID_{len(audio_data)}"
                
                audio_data.append({
                    "id": audio_id,
                    "filename": filename,
                    "audio_url": audio_url,
                    "chinese_text": chinese_text
                })
    else:
        # è°ƒè¯•åŠŸèƒ½ä¾ç„¶ä¿ç•™ï¼Œä»¥é˜²ä¸‡ä¸€
        print(f"!! è­¦å‘Š: åœ¨é¡µé¢ '{page_title}' ä¸­æœªæ‰¾åˆ°ä»»ä½• class='downloadable-audio' çš„å†…å®¹å—ã€‚")
        print(f"   é¡µé¢URL: {page_url}")
        
        debug_dir = Path("debug")
        debug_dir.mkdir(exist_ok=True)
        filename = f"debug_{page_title.replace('/', '_').replace(':', '_')}.html"
        debug_path = debug_dir / filename
        with open(debug_path, 'w', encoding='utf-8') as f:
            f.write(soup.prettify())
        print(f"   è¯¥é¡µé¢çš„HTMLå†…å®¹å·²ä¿å­˜åˆ°: {debug_path.absolute()}")

    return {
        "page_title": page_title,
        "total_count": len(audio_data),
        "audio_list": audio_data
    }

def download_audio_and_text(audio_item: dict, output_dir: Path, session: httpx.Client) -> bool:
    """
    ä¸‹è½½å•ä¸ªéŸ³é¢‘æ–‡ä»¶å¹¶ä¿å­˜å¯¹åº”çš„æ–‡æœ¬æ–‡ä»¶ã€‚
    """
    audio_id = audio_item['id']
    audio_url = audio_item['audio_url']
    chinese_text = audio_item['chinese_text']
    
    audio_filename = f"{audio_id}.ogg"
    text_filename = f"{audio_id}.txt"
    
    audio_path = output_dir / audio_filename
    text_path = output_dir / text_filename
    
    try:
        if audio_path.exists() and text_path.exists():
            return True
            
        print(f"ä¸‹è½½éŸ³é¢‘: {audio_id} | æ–‡æœ¬: {chinese_text}")
        audio_response = session.get(audio_url)
        audio_response.raise_for_status()
        
        with open(audio_path, 'wb') as f:
            f.write(audio_response.content)
        
        with open(text_path, 'w', encoding='utf-8') as f:
            f.write(chinese_text)
        
        return True
        
    except Exception as e:
        print(f"ä¸‹è½½å¤±è´¥ {audio_id}: {e}")
        if audio_path.exists(): os.remove(audio_path)
        if text_path.exists(): os.remove(text_path)
        return False

def main():
    """
    ä¸»å‡½æ•°ï¼Œåè°ƒæ•´ä¸ªçˆ¬å–å’Œä¸‹è½½è¿‡ç¨‹ã€‚
    """
    character_url = "https://voicewiki.cn/wiki/%E8%8E%B1%E5%9B%A0%E5%93%88%E7%89%B9%EF%BC%88%E5%AE%88%E6%9C%9B%E5%85%88%E9%94%8B%EF%BC%89"

    try:
        character_name_full = unquote(character_url.split('/wiki/')[-1])
        character_name = re.sub(r'ï¼ˆ.*?ï¼‰', '', character_name_full).strip()
    except IndexError:
        character_name = "character_data"

    output_dir = Path(f"data/{character_name}")
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"æ‰€æœ‰æ–‡ä»¶å°†è¢«ä¿å­˜åˆ°: {output_dir.absolute()}")

    with httpx.Client(timeout=30.0, follow_redirects=True) as session:
        voice_page_urls = get_voice_page_urls(character_url, session)
        
        if not voice_page_urls:
            print("æœªèƒ½è·å–ä»»ä½•è¯­éŸ³é¡µé¢é“¾æ¥ï¼Œç¨‹åºé€€å‡ºã€‚")
            return
        
        total_downloaded = 0
        total_failed = 0

        for page_url in voice_page_urls:
            try:
                print(f"\n{'='*20}\næ­£åœ¨å¤„ç†é¡µé¢: {unquote(page_url)}\n{'='*20}")
                page_response = session.get(page_url)
                page_response.raise_for_status()

                voice_data = parse_voice_page(page_response.text, page_url)
                
                if voice_data["total_count"] == 0:
                    continue

                print(f"é¡µé¢ '{voice_data['page_title']}' æ‰¾åˆ° {voice_data['total_count']} æ¡è¯­éŸ³ï¼Œå¼€å§‹ä¸‹è½½...")

                for i, audio_item in enumerate(voice_data['audio_list'], 1):
                    print(f"[{i}/{voice_data['total_count']}] ", end="")
                    if download_audio_and_text(audio_item, output_dir, session):
                        total_downloaded += 1
                    else:
                        total_failed += 1
                    time.sleep(0.2)

            except Exception as e:
                print(f"\nå¤„ç†é¡µé¢ {page_url} æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
                total_failed += 1
    
    print("\n\nğŸ‰ å…¨éƒ¨ä»»åŠ¡å®Œæˆï¼ ğŸ‰")
    print(f"æ€»è®¡æˆåŠŸä¸‹è½½: {total_downloaded} ä¸ªæ–‡ä»¶")
    if total_failed > 0:
        print(f"æ€»è®¡ä¸‹è½½å¤±è´¥: {total_failed} ä¸ªæ–‡ä»¶")
    print(f"æ•°æ®å­˜æ”¾åœ¨ç›®å½•: {output_dir.absolute()}")

if __name__ == "__main__":
    main()