#############################################
# Core audio processing
#############################################
numpy<=1.26.4
librosa>=0.10.1
soundfile>=0.12.1
tqdm>=4.64.0

#############################################
# Web crawling
#############################################
requests>=2.31.0
httpx>=0.24.0
beautifulsoup4>=4.12.0

#############################################
# Source separation (UVR via Demucs)
#############################################
# first as it's torch dependency is the 2.0.1
git+https://github.com/facebookresearch/demucs#egg=demucs

#############################################
# Models and VAD
#############################################
faster-whisper
huggingface-hub
funasr
silero-vad
ten-vad
qwen-asr
qwen-asr[vllm]
#############################################
# Deep learning runtime (install torch/torchaudio per platform/CUDA)
#############################################
torch
torchaudio

#############################################
# LLM APIs and Multimodal Utilities
#############################################
openai>=1.0.0
transformers
modelscope
qwen_omni_utils

#############################################
# Distillation and Third-party SDKs
#############################################
websockets
fish-audio-sdk

#############################################
# Optional: vLLM acceleration (Linux only)
#############################################
# Uncomment on Linux if you plan to use run_whisper.py or Qwen-Omni with vLLM
# vllm>=0.10.0
